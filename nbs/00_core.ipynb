{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello-World DSPy Agent\n",
    "\n",
    "> A minimal DSPy agent implementation to echo or compute simple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cvardema/dev/git/LA3D/cogitarelink/cogitarelink-dspy/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import dspy\n",
    "import os\n",
    "\n",
    "# Configure a default LLM - using gpt-4o-mini as specified in the plan\n",
    "# Note: In real usage, you'd set OPENAI_API_KEY in your environment\n",
    "default_lm = dspy.LM(\"openai/gpt-4o-mini\")\n",
    "dspy.configure(lm=default_lm)\n",
    "\n",
    "class Echo(dspy.Module):\n",
    "    \"\"\"Echoes the input message back.\"\"\"\n",
    "    def forward(self, message: str) -> str:\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_hello_agent(llm=None):\n",
    "    \"\"\"Create a simple DSPy agent with the Echo tool and LLM capabilities.\n",
    "    \n",
    "    Args:\n",
    "        llm: A DSPy language model. If None, uses the default configured LM.\n",
    "    \n",
    "    Returns:\n",
    "        A HelloAgent instance that can process messages using the Echo tool and LLM.\n",
    "    \"\"\"\n",
    "    # Use provided LLM or the default one\n",
    "    lm = llm or dspy.settings.lm\n",
    "    \n",
    "    # Create a simple signature for LLM-based response generation\n",
    "    signature = dspy.Signature(\n",
    "        \"message -> response\",\n",
    "        \"Generate a friendly response to the input message.\"\n",
    "    )\n",
    "    \n",
    "    # Create an Agent class that can use Echo tool and LLM\n",
    "    class HelloAgent(dspy.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.tools = [Echo()]\n",
    "            # Use ChainOfThought module to get LLM reasoning\n",
    "            self.predictor = dspy.ChainOfThought(signature)\n",
    "            \n",
    "        def forward(self, message):\n",
    "            # First use the Echo tool\n",
    "            echo_result = self.tools[0].forward(message)\n",
    "            \n",
    "            # Then get an LLM response\n",
    "            llm_result = self.predictor(message=message)\n",
    "            \n",
    "            # Return both results\n",
    "            return {\n",
    "                \"echo_result\": echo_result,\n",
    "                \"llm_response\": llm_result.response,\n",
    "                \"reasoning\": getattr(llm_result, \"reasoning\", None)\n",
    "            }\n",
    "            \n",
    "    # Return a new instance of the HelloAgent\n",
    "    return HelloAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echo result: Hello, DSPy! What can you do with Semantic Web data?\n",
      "\n",
      "LLM response: Hello! Great question! DSPy can work with Semantic Web data in various exciting ways. We can help with data integration, allowing you to combine information from different sources seamlessly. Additionally, we can assist in knowledge representation, making it easier to model complex relationships and concepts. Enhanced querying capabilities also mean you can extract meaningful insights from your data more efficiently. If you have specific use cases in mind, feel free to share, and Iâ€™d be happy to dive deeper!\n",
      "\n",
      "LLM reasoning: The user is inquiring about the capabilities of DSPy in relation to Semantic Web data. A friendly and informative response should highlight the potential uses of Semantic Web data, such as data integration, knowledge representation, and enhanced data querying. It's important to convey enthusiasm and openness to further questions.\n"
     ]
    }
   ],
   "source": [
    "# Demo the Hello-World agent with LLM capabilities\n",
    "agent = make_hello_agent()\n",
    "message = \"Hello, DSPy! What can you do with Semantic Web data?\"\n",
    "result = agent(message)\n",
    "\n",
    "print(\"Echo result:\", result[\"echo_result\"])\n",
    "print(\"\\nLLM response:\", result[\"llm_response\"])\n",
    "print(\"\\nLLM reasoning:\", result[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
