{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af482848",
   "metadata": {},
   "source": [
    "# Structured Agents and Pipelines\n",
    "> Creating DSPy StructuredAgents for Semantic Web tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe846d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COG_LOGLEVEL\"] = \"DEBUG\"\n",
    "# or, programmatically:\n",
    "from cogitarelink.core.debug import set_loglevel\n",
    "set_loglevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Any, Optional\n",
    "import dspy, hashlib, datetime\n",
    "from cogitarelink.core.graph import GraphManager\n",
    "from cogitarelink_dspy.wrappers import get_tools, get_tool_by_name, group_tools_by_layer\n",
    "from cogitarelink_dspy.components import list_layers\n",
    "from cogitarelink_dspy.memory import ReflectionStore, REFLECTION_GRAPH\n",
    "from cogitarelink_dspy.telemetry import TelemetryStore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722663e0",
   "metadata": {},
   "source": [
    "## Setup mlflow for logging and introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.set_experiment(\"DSPy\")\n",
    "mlflow.dspy.autolog()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeec3c8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook implements structured agent pipelines for the Cogitarelink-DSPy integration. We're creating agents that can reason about semantic web data across different layers of abstraction:\n",
    "\n",
    "1. **Context Layer** - Working with JSON-LD contexts and namespaces\n",
    "2. **Ontology Layer** - Exploring ontologies and vocabularies\n",
    "3. **Rules Layer** - Validating data against rules (SHACL, etc.)\n",
    "4. **Instances Layer** - Working with actual data/triples\n",
    "5. **Verification Layer** - Verifying and signing data\n",
    "\n",
    "In addition, we have a **Utility Layer** for cross-cutting concerns like memory and telemetry.\n",
    "\n",
    "Our approach uses DSPy's `StructuredAgent` which provides a framework for tool selection and execution based on the user's query. We'll implement two levels of agents:\n",
    "\n",
    "- `HelloLOD`: A lightweight agent with essential tools for common tasks\n",
    "- `FullPlanner`: A comprehensive agent with all available tools\n",
    "\n",
    "We'll also integrate memory capabilities to enable the agent to learn from previous experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b00069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "graph     = GraphManager(use_rdflib=True)\n",
    "mem       = ReflectionStore(graph)\n",
    "telemetry = TelemetryStore(graph)\n",
    "\n",
    "TOOLS = get_tools()\n",
    "TOOLS += [mem.add, mem.retrieve, mem.as_prompt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201bb53",
   "metadata": {},
   "source": [
    "## System Prompts\n",
    "\n",
    "The heart of our agent's reasoning is the system prompt, which explains the semantic web layers and how to select the appropriate tool based on the user's query. Let's define the system prompts for our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2716ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for ReAct agent\n",
    "SEM_WEB_SYSTEM = (\n",
    "    \"You are a Linked-Data teaching assistant. \"\n",
    "    \"Think step-by-step; choose the highest Cogitarelink layer that solves the task. \"\n",
    "    \"Return only the final answer â€” never reveal your thought.\"\n",
    ")\n",
    "\n",
    "# Define the ReAct signature\n",
    "sig = dspy.Signature(\n",
    "    \"query:str -> answer:str\",\n",
    "    instructions=SEM_WEB_SYSTEM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LLM and instantiate the ReAct agent\n",
    "lm = dspy.LM(\n",
    "    \"openai/o3-mini\",\n",
    "    temperature=1.0,\n",
    "    max_tokens=20000\n",
    ")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae72d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dspy.clients.lm.LM>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\n",
    "    signature=sig,\n",
    "    tools=TOOLS,\n",
    "    max_iters=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3d93e",
   "metadata": {},
   "source": [
    "## HelloLOD: Lightweight Semantic Web Agent\n",
    "\n",
    "Our `HelloLOD` agent is a minimal implementation that provides basic semantic web functionality. It includes only the essential tools for common tasks, making it faster and more focused than the full agent.\n",
    "\n",
    "The key design decisions for HelloLOD are:\n",
    "\n",
    "1. Include one representative tool from each semantic layer\n",
    "2. Exclude memory tools initially for simplicity\n",
    "3. Use a straightforward system prompt without complex reflection\n",
    "\n",
    "This agent serves as both a proof of concept and a starting point for more complex implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HelloLOD(dspy.Module):\n",
    "    \"\"\"Lightweight wrapper that logs scratch-pad hashes & provenance.\"\"\"\n",
    "    def __init__(self, agent, telemetry, mem):\n",
    "        super().__init__()\n",
    "        self.agent = agent\n",
    "        self.telemetry = telemetry\n",
    "        self.mem = mem\n",
    "\n",
    "    def forward(self, query: str):\n",
    "        t0 = datetime.datetime.utcnow()\n",
    "        result = self.agent(query=query)\n",
    "        t1 = datetime.datetime.utcnow()\n",
    "\n",
    "        # Hash the hidden chain-of-thought (fallback to empty if unavailable)\n",
    "        try:\n",
    "            lm = self.agent.get_lm()\n",
    "        except Exception:\n",
    "            lm = None\n",
    "        scratch = getattr(lm, \"last_scratch\", \"\") if lm is not None else \"\"\n",
    "        digest = hashlib.sha256(scratch.encode()).hexdigest()\n",
    "        self.telemetry.log(\"cot\", digest, tool_iri=\"urn:agent:HelloLOD\")\n",
    "\n",
    "        # Log latency (milliseconds)\n",
    "        latency_ms = (t1 - t0).total_seconds() * 1000\n",
    "        self.telemetry.log(\"latency\", latency_ms, tool_iri=\"urn:agent:HelloLOD\")\n",
    "\n",
    "        # Optional manual reflection\n",
    "        if query.lower().startswith(\"remember:\"):\n",
    "            note = query.split(\"remember:\", 1)[1].strip()\n",
    "            self.mem.add(note, tags=[\"manual\"])\n",
    "            return {\"answer\": f\"Stored: {note}\"}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2128ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "hello = HelloLOD(agent, telemetry, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad46561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple of sample queries to exercise each layer\n",
    "test_queries = [\n",
    "    \"What is the full IRI of dc:title?\",\n",
    "    \"How many cats on Wikidata?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d72672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:    What is the full IRI of dc:title?\n",
      "Answer:   http://purl.org/dc/elements/1.1/title\n",
      "Trajectory: {'thought_0': 'The full IRI for dc:title is \"http://purl.org/dc/elements/1.1/title\".', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "------------------------------------------------------------\n",
      "Query:    How many cats on Wikidata?\n",
      "Answer:   There isnâ€™t a fixed numberâ€”the current count is dynamic. To get the exact number, run the query: SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }.\n",
      "Trajectory: {'thought_0': 'The question asks for the number of cat items on Wikidata. Since Wikidata is continuously updated, a direct number isnâ€™t fixed; instead one would typically determine the count by running a SPARQL query such as:\\n  SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }\\nThis query counts all items that have the instance-of property (P31) pointing to the \"cat\" entity (Q146). The returned number will reflect the current state of Wikidata and can vary over time.', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for q in test_queries:\n",
    "    print(f\"Query:    {q}\")\n",
    "    resp = hello(q)\n",
    "    # DSPy Prediction objects have .answer and .trajectory attributes\n",
    "    answer     = getattr(resp, \"answer\", resp.get(\"answer\", None))\n",
    "    trajectory = getattr(resp, \"trajectory\", resp.get(\"trace\", None))\n",
    "    print(f\"Answer:   {answer}\")\n",
    "    print(f\"Trajectory: {trajectory}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e77f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACE â†’ {'thought_0': 'The full IRI for dc:title is \"http://purl.org/dc/elements/1.1/title\".', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n"
     ]
    }
   ],
   "source": [
    " # HelloLOD\n",
    "resp = hello(\"What is the full IRI of dc:title?\")\n",
    "print(\"TRACE â†’\", resp.trajectory)      # which tool was picked\n",
    "# check stderr for any cogitarelink.* DEBUG messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce640591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACE â†’ {'thought_0': 'The question asks for the number of cat items on Wikidata. Since Wikidata is continuously updated, a direct number isnâ€™t fixed; instead one would typically determine the count by running a SPARQL query such as:\\n  SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }\\nThis query counts all items that have the instance-of property (P31) pointing to the \"cat\" entity (Q146). The returned number will reflect the current state of Wikidata and can vary over time.', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "OBSERVATION â†’ There isnâ€™t a fixed numberâ€”the current count is dynamic. To get the exact number, run the query: SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }.\n"
     ]
    }
   ],
   "source": [
    "resp = hello(\"How many cats on Wikidata?\")\n",
    "print(\"TRACE â†’\", resp.trajectory)\n",
    "print(\"OBSERVATION â†’\", resp.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've implemented a layered approach to semantic web agents using DSPy's structured agent framework. The key components we've created are:\n",
    "\n",
    "1. **System prompts** that explain the semantic web layers and guide tool selection\n",
    "2. **Agent implementations** at different capability levels (HelloLOD, HelloLODWithMemory, FullPlanner)\n",
    "3. **Memory integration** to learn from past interactions\n",
    "4. **Testing utilities** to validate agent behavior\n",
    "\n",
    "These components form the foundation of our semantic web agent architecture, enabling sophisticated reasoning across the different layers of the semantic web stack. The agents can now be integrated into applications to provide semantic web capabilities through natural language interfaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
