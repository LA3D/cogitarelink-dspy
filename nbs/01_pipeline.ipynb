{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af482848",
   "metadata": {},
   "source": [
    "# Structured Agents and Pipelines\n",
    "> Creating DSPy StructuredAgents for Semantic Web tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe846d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COG_LOGLEVEL\"] = \"DEBUG\"\n",
    "# or, programmatically:\n",
    "from cogitarelink.core.debug import set_loglevel\n",
    "set_loglevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Any, Optional\n",
    "import dspy, hashlib, datetime\n",
    "from cogitarelink.core.graph import GraphManager\n",
    "from cogitarelink_dspy.wrappers import get_tools, get_tool_by_name, group_tools_by_layer\n",
    "from cogitarelink_dspy.components import list_layers\n",
    "from cogitarelink_dspy.memory import ReflectionStore, REFLECTION_GRAPH\n",
    "from cogitarelink_dspy.telemetry import TelemetryStore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722663e0",
   "metadata": {},
   "source": [
    "## Setup mlflow for logging and introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.set_experiment(\"DSPy\")\n",
    "mlflow.dspy.autolog()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeec3c8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook implements structured agent pipelines for the Cogitarelink-DSPy integration. We're creating agents that can reason about semantic web data across different layers of abstraction:\n",
    "\n",
    "1. **Context Layer** - Working with JSON-LD contexts and namespaces\n",
    "2. **Ontology Layer** - Exploring ontologies and vocabularies\n",
    "3. **Rules Layer** - Validating data against rules (SHACL, etc.)\n",
    "4. **Instances Layer** - Working with actual data/triples\n",
    "5. **Verification Layer** - Verifying and signing data\n",
    "\n",
    "In addition, we have a **Utility Layer** for cross-cutting concerns like memory and telemetry.\n",
    "\n",
    "Our approach uses DSPy's `StructuredAgent` which provides a framework for tool selection and execution based on the user's query. We'll implement two levels of agents:\n",
    "\n",
    "- `HelloLOD`: A lightweight agent with essential tools for common tasks\n",
    "- `FullPlanner`: A comprehensive agent with all available tools\n",
    "\n",
    "We'll also integrate memory capabilities to enable the agent to learn from previous experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b00069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "graph     = GraphManager(use_rdflib=True)\n",
    "mem       = ReflectionStore(graph)\n",
    "telemetry = TelemetryStore(graph)\n",
    "\n",
    "TOOLS = get_tools()\n",
    "TOOLS += [mem.add, mem.retrieve, mem.as_prompt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201bb53",
   "metadata": {},
   "source": [
    "## System Prompts\n",
    "\n",
    "The heart of our agent's reasoning is the system prompt, which explains the semantic web layers and how to select the appropriate tool based on the user's query. Let's define the system prompts for our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2716ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for ReAct agent\n",
    "SEM_WEB_SYSTEM = (\n",
    "    \"You are a Linked-Data teaching assistant. \"\n",
    "    \"Think step-by-step; choose the highest Cogitarelink layer that solves the task. \"\n",
    "    \"Return only the final answer — never reveal your thought.\"\n",
    ")\n",
    "\n",
    "# Define the ReAct signature\n",
    "sig = dspy.Signature(\n",
    "    \"query:str -> answer:str\",\n",
    "    instructions=SEM_WEB_SYSTEM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LLM and instantiate the ReAct agent\n",
    "lm = dspy.LM(\n",
    "    \"openai/o3-mini\",\n",
    "    temperature=1.0,\n",
    "    max_tokens=20000\n",
    ")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae72d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dspy.clients.lm.LM>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\n",
    "    signature=sig,\n",
    "    tools=TOOLS,\n",
    "    max_iters=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3d93e",
   "metadata": {},
   "source": [
    "## HelloLOD: Lightweight Semantic Web Agent\n",
    "\n",
    "Our `HelloLOD` agent is a minimal implementation that provides basic semantic web functionality. It includes only the essential tools for common tasks, making it faster and more focused than the full agent.\n",
    "\n",
    "The key design decisions for HelloLOD are:\n",
    "\n",
    "1. Include one representative tool from each semantic layer\n",
    "2. Exclude memory tools initially for simplicity\n",
    "3. Use a straightforward system prompt without complex reflection\n",
    "\n",
    "This agent serves as both a proof of concept and a starting point for more complex implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HelloLOD(dspy.Module):\n",
    "    \"\"\"Lightweight wrapper that logs scratch-pad hashes & provenance.\"\"\"\n",
    "    def __init__(self, agent, telemetry, mem):\n",
    "        super().__init__()\n",
    "        self.agent = agent\n",
    "        self.telemetry = telemetry\n",
    "        self.mem = mem\n",
    "\n",
    "    def forward(self, query: str):\n",
    "        t0 = datetime.datetime.utcnow()\n",
    "        result = self.agent(query=query)\n",
    "        t1 = datetime.datetime.utcnow()\n",
    "\n",
    "        # Hash the hidden chain-of-thought (fallback to empty if unavailable)\n",
    "        try:\n",
    "            lm = self.agent.get_lm()\n",
    "        except Exception:\n",
    "            lm = None\n",
    "        scratch = getattr(lm, \"last_scratch\", \"\") if lm is not None else \"\"\n",
    "        digest = hashlib.sha256(scratch.encode()).hexdigest()\n",
    "        self.telemetry.log(\"cot\", digest, tool_iri=\"urn:agent:HelloLOD\")\n",
    "\n",
    "        # Log latency (milliseconds)\n",
    "        latency_ms = (t1 - t0).total_seconds() * 1000\n",
    "        self.telemetry.log(\"latency\", latency_ms, tool_iri=\"urn:agent:HelloLOD\")\n",
    "\n",
    "        # Optional manual reflection\n",
    "        if query.lower().startswith(\"remember:\"):\n",
    "            note = query.split(\"remember:\", 1)[1].strip()\n",
    "            self.mem.add(note, tags=[\"manual\"])\n",
    "            return {\"answer\": f\"Stored: {note}\"}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2128ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "hello = HelloLOD(agent, telemetry, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad46561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple of sample queries to exercise each layer\n",
    "test_queries = [\n",
    "    \"What is the full IRI of dc:title?\",\n",
    "    \"How many cats on Wikidata?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d72672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:21:51 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:    What is the full IRI of dc:title?\n",
      "Answer:   http://purl.org/dc/elements/1.1/title\n",
      "Trajectory: {'thought_0': 'The full IRI for dc:title is \"http://purl.org/dc/elements/1.1/title\".', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "------------------------------------------------------------\n",
      "Query:    How many cats on Wikidata?\n",
      "Answer:   There isn’t a fixed number—the current count is dynamic. To get the exact number, run the query: SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }.\n",
      "Trajectory: {'thought_0': 'The question asks for the number of cat items on Wikidata. Since Wikidata is continuously updated, a direct number isn’t fixed; instead one would typically determine the count by running a SPARQL query such as:\\n  SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }\\nThis query counts all items that have the instance-of property (P31) pointing to the \"cat\" entity (Q146). The returned number will reflect the current state of Wikidata and can vary over time.', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for q in test_queries:\n",
    "    print(f\"Query:    {q}\")\n",
    "    resp = hello(q)\n",
    "    # DSPy Prediction objects have .answer and .trajectory attributes\n",
    "    answer     = getattr(resp, \"answer\", resp.get(\"answer\", None))\n",
    "    trajectory = getattr(resp, \"trajectory\", resp.get(\"trace\", None))\n",
    "    print(f\"Answer:   {answer}\")\n",
    "    print(f\"Trajectory: {trajectory}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e77f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:22:24 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACE → {'thought_0': 'The full IRI for dc:title is \"http://purl.org/dc/elements/1.1/title\".', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n"
     ]
    }
   ],
   "source": [
    " # HelloLOD\n",
    "resp = hello(\"What is the full IRI of dc:title?\")\n",
    "print(\"TRACE →\", resp.trajectory)      # which tool was picked\n",
    "# check stderr for any cogitarelink.* DEBUG messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce640591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace HelloLOD.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ReAct.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChainOfThought.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace Predict.forward: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.format: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace LM.__call__: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n",
      "2025/05/15 12:23:01 WARNING mlflow.tracking.client: Failed to start trace ChatAdapter.parse: API request to endpoint /api/2.0/mlflow/traces failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACE → {'thought_0': 'The question asks for the number of cat items on Wikidata. Since Wikidata is continuously updated, a direct number isn’t fixed; instead one would typically determine the count by running a SPARQL query such as:\\n  SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }\\nThis query counts all items that have the instance-of property (P31) pointing to the \"cat\" entity (Q146). The returned number will reflect the current state of Wikidata and can vary over time.', 'tool_name_0': 'finish', 'tool_args_0': {}, 'observation_0': 'Completed.'}\n",
      "OBSERVATION → There isn’t a fixed number—the current count is dynamic. To get the exact number, run the query: SELECT (COUNT(?cat) AS ?count) WHERE { ?cat wdt:P31 wd:Q146 }.\n"
     ]
    }
   ],
   "source": [
    "resp = hello(\"How many cats on Wikidata?\")\n",
    "print(\"TRACE →\", resp.trajectory)\n",
    "print(\"OBSERVATION →\", resp.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44342bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wrappers generated: 22\n",
      "['EchoMessage', 'LoadContext', 'FetchOntology', 'ValidateEntity', 'GraphManager', 'VerifySignature', 'AddReflection', 'RecallReflection', 'ReflectionPrompt', 'LogTelemetry', 'add', 'retrieve', 'as_prompt', 'add', 'retrieve', 'as_prompt', 'add', 'retrieve', 'as_prompt', 'add', 'retrieve', 'as_prompt']\n"
     ]
    }
   ],
   "source": [
    "from cogitarelink_dspy.wrappers import get_tools\n",
    "tools = get_tools()\n",
    "print(f\"Total wrappers generated: {len(tools)}\")\n",
    "print([t.__name__ for t in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da85d6a",
   "metadata": {},
   "source": [
    "## Memory-Focused Training\n",
    "\n",
    "Now we'll implement a training pipeline for our agent using a memory-focused development set. This approach follows DSPy's training methodology to optimize the agent's ability to use the memory tools appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33 memory examples\n",
      "Example 1:\n",
      "Query: Remember that wdt:P1476 is title\n",
      "Expected Tool: AddReflection\n",
      "Use Memory: False\n",
      "---\n",
      "Example 2:\n",
      "Query: What's the Wikidata title property?\n",
      "Expected Tool: RecallReflection\n",
      "Use Memory: True\n",
      "---\n",
      "Example 3:\n",
      "Query: Inject notes into system prompt\n",
      "Expected Tool: ReflectionPrompt\n",
      "Use Memory: False\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 1. First, let's load and inspect the memory development set\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_memory_devset(path=\"../tests/devset_memory.jsonl\"):\n",
    "    \"\"\"Load the memory development set from JSONL.\"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Convert to DSPy Example format\n",
    "            example = dspy.Example(\n",
    "                q=data[\"q\"],\n",
    "                exp_tool=data[\"exp_tool\"],\n",
    "                use_memory=data.get(\"use_memory\", False)\n",
    "            ).with_inputs(\"q\")\n",
    "            examples.append(example)\n",
    "            \n",
    "    return examples\n",
    "\n",
    "# Load and display a few examples\n",
    "memory_devset = load_memory_devset()\n",
    "print(f\"Loaded {len(memory_devset)} memory examples\")\n",
    "\n",
    "for i, example in enumerate(memory_devset[:3]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Query: {example.q}\")\n",
    "    print(f\"Expected Tool: {example.exp_tool}\")\n",
    "    print(f\"Use Memory: {example.use_memory}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a metric function for evaluating tool selection\n",
    "def tool_match(pred, sample):\n",
    "    \"\"\"Check if the expected tool is in the trace.\"\"\"\n",
    "    # For ReAct's trajectory output format\n",
    "    if hasattr(pred, 'trajectory') and pred.trajectory:\n",
    "        tools_used = [t.get('tool_name') for t in pred.trajectory.values() \n",
    "                     if isinstance(t, dict) and 'tool_name' in t]\n",
    "        return sample.exp_tool in tools_used\n",
    "    \n",
    "    # For other output formats\n",
    "    return sample.exp_tool in getattr(pred, 'trace', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define a memory-focused agent for training\n",
    "class MemoryAgent(dspy.Module):\n",
    "    \"\"\"A DSPy agent focused on memory operations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define submodules for different decisions\n",
    "        self.decide_memory_action = dspy.ChainOfThought(\"q -> memory_action\")\n",
    "        \n",
    "        # Define memory-related tools\n",
    "        memory_tools = [tool for tool in TOOLS \n",
    "                       if tool.__name__ in [\"AddReflection\", \"RecallReflection\", \"ReflectionPrompt\"]]\n",
    "        \n",
    "        # Create a ReAct agent for execution\n",
    "        self.executor = dspy.ReAct(\n",
    "            signature=dspy.Signature(\n",
    "                \"query:str -> answer:str\",\n",
    "                instructions=\"You are a memory assistant that can store and recall information.\"\n",
    "            ),\n",
    "            tools=memory_tools,\n",
    "            max_iters=3\n",
    "        )\n",
    "    \n",
    "    def forward(self, q):\n",
    "        # Decide what memory action to take\n",
    "        memory_decision = self.decide_memory_action(q=q)\n",
    "        \n",
    "        # Execute with ReAct\n",
    "        result = self.executor(query=q)\n",
    "        \n",
    "        # Add tool trace for evaluation\n",
    "        result.trace = []\n",
    "        if hasattr(result, 'trajectory'):\n",
    "            for step in result.trajectory.values():\n",
    "                if isinstance(step, dict) and 'tool_name' in step:\n",
    "                    result.trace.append(step['tool_name'])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c1e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 26 examples, validating on 7 examples\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BootstrapFewShot.__init__() got an unexpected keyword argument 'trainset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m memory_agent = MemoryAgent()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Define the bootstrap trainer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m bootstrap = \u001b[43mBootstrapFewShot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Start with a small subset for demonstration\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your machine\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: BootstrapFewShot.__init__() got an unexpected keyword argument 'trainset'"
     ]
    }
   ],
   "source": [
    "# 4. Set up bootstrap training\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_examples, val_examples = train_test_split(\n",
    "    memory_devset, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training on {len(train_examples)} examples, validating on {len(val_examples)} examples\")\n",
    "\n",
    "# Create the base agent\n",
    "memory_agent = MemoryAgent()\n",
    "\n",
    "# Define the bootstrap trainer\n",
    "bootstrap = BootstrapFewShot(\n",
    "    trainset=train_examples[:5],  # Start with a small subset for demonstration\n",
    "    metric=tool_match,\n",
    "    num_threads=1  # Adjust based on your machine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Run compilation (commented out to avoid LLM costs during development)\n",
    "# Optimize using DSPy's compilation framework\n",
    "# optimized_agent = dspy.compile(memory_agent, bootstrap, num_iterations=2)\n",
    "\n",
    "# For demonstration/development, we'll use the unoptimized version\n",
    "optimized_agent = memory_agent\n",
    "\n",
    "print(\"Using unoptimized agent for demonstration. Uncomment to run actual training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ba515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate the agent\n",
    "def evaluate_agent(agent, examples):\n",
    "    \"\"\"Evaluate an agent on a set of examples.\"\"\"\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    for example in examples:\n",
    "        pred = agent(example.q)\n",
    "        is_correct = tool_match(pred, example)\n",
    "        \n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"query\": example.q,\n",
    "            \"expected\": example.exp_tool,\n",
    "            \"predicted\": getattr(pred, 'trace', []),\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "    \n",
    "    accuracy = correct / len(examples) if examples else 0\n",
    "    return accuracy, results\n",
    "\n",
    "# Evaluate on a small subset to demonstrate the process\n",
    "sample_examples = val_examples[:5]  # Using just a few examples for demonstration\n",
    "val_accuracy, val_results = evaluate_agent(optimized_agent, sample_examples)\n",
    "print(f\"Validation accuracy on sample: {val_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd268a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Display example predictions\n",
    "print(\"\\nExample predictions:\")\n",
    "for i, result in enumerate(val_results[:3]):\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(f\"Expected: {result['expected']}\")\n",
    "    print(f\"Predicted: {result['predicted']}\")\n",
    "    print(f\"Correct: {result['correct']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the optimized agent (commented out for demonstration)\n",
    "# import pickle\n",
    "# import os\n",
    "# \n",
    "# def save_agent(agent, path):\n",
    "#     \"\"\"Save the optimized agent to disk.\"\"\"\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     with open(path, 'wb') as f:\n",
    "#         pickle.dump(agent, f)\n",
    "#     return path\n",
    "# \n",
    "# # saved_path = save_agent(optimized_agent, \"../cogitarelink_dspy/optimized/memory_agent.pkl\")\n",
    "# # print(f\"Saved optimized agent to {saved_path}\")\n",
    "\n",
    "print(\"Model saving is commented out for demonstration purposes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd214e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Integration with HelloLOD\n",
    "class HelloLODWithMemory(HelloLOD):\n",
    "    \"\"\"HelloLOD agent with integrated memory capabilities.\"\"\"\n",
    "    \n",
    "    def forward(self, query: str):\n",
    "        # First check if this is a memory operation\n",
    "        if any(kw in query.lower() for kw in [\"remember\", \"recall\", \"what did\", \"inject\"]):\n",
    "            # Use the memory agent for memory-specific operations\n",
    "            memory_result = optimized_agent(query)\n",
    "            \n",
    "            # Extract the answer for the user\n",
    "            answer = getattr(memory_result, \"answer\", \"Memory operation completed\")\n",
    "            \n",
    "            # Log memory usage telemetry\n",
    "            self.telemetry.log(\"memory_use\", 1, tool_iri=\"urn:agent:HelloLODWithMemory\")\n",
    "            \n",
    "            return {\"answer\": answer}\n",
    "        \n",
    "        # Otherwise, use the standard HelloLOD behavior\n",
    "        return super().forward(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the integrated agent\n",
    "hello_with_memory = HelloLODWithMemory(agent, telemetry, mem)\n",
    "\n",
    "# Test with a memory-related query\n",
    "memory_query = \"Remember that rdfs:label is used for human-readable labels\"\n",
    "print(f\"Query: {memory_query}\")\n",
    "resp = hello_with_memory(memory_query)\n",
    "print(f\"Response: {resp.get('answer', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69ebbd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've implemented a layered approach to semantic web agents using DSPy's structured agent framework. The key components we've created are:\n",
    "\n",
    "1. **System prompts** that explain the semantic web layers and guide tool selection\n",
    "2. **Agent implementations** at different capability levels (HelloLOD, HelloLODWithMemory)\n",
    "3. **Memory integration** with a training pipeline based on a curriculum dataset\n",
    "4. **Evaluation metrics** to measure performance on memory tasks\n",
    "\n",
    "This implementation follows Jeremy Howard's step-by-step approach:\n",
    "- Starting with simple, working demonstrations\n",
    "- Building complexity incrementally\n",
    "- Documenting each step clearly\n",
    "- Testing components in isolation before integration\n",
    "\n",
    "The next steps would be to:\n",
    "1. Run the training with a real LLM\n",
    "2. Expand the curriculum dataset to cover more semantic web tasks\n",
    "3. Implement advanced techniques like reflection garbage collection\n",
    "4. Create a full evaluation suite for comprehensive testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
